{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ce5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import chardet\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import collections\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b51e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "# Lower security level to allow weak DH keys\n",
    "ssl_context = ssl.create_default_context()\n",
    "ssl_context.set_ciphers('DEFAULT:@SECLEVEL=1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757b89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "POPPLER_PATH = '/usr/bin'\n",
    "TESSERACT_CMD = '/usr/bin/tesseract'\n",
    "BASE_PATH = '/workspace'\n",
    "PATH_DATA = BASE_PATH + '/data/'\n",
    "PATH_PDF = BASE_PATH + '/pdf/'\n",
    "PATH_TXT = BASE_PATH + '/text/'\n",
    "PATH_TMP = BASE_PATH + '/temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a941813",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utility Functions ---\n",
    "\n",
    "def detect_encoding(filepath):\n",
    "    with open(filepath, 'rb') as rawdata:\n",
    "        return chardet.detect(rawdata.read(10000)).get(\"encoding\")\n",
    "\n",
    "def download_pdfs(data_list, path_pdf):\n",
    "    pdf_list = [join(path_pdf, i) for i in listdir(path_pdf)]\n",
    "    pdf_list = [w.replace('.pdf', '') for w in pdf_list]\n",
    "    pdf_list = [w.replace(path_pdf, 'https://prodapp2.seace.gob.pe/portalseace-uiwd-pub/DownloadContratosFileServlet?fileName=') for w in pdf_list]\n",
    "    todownload_list = list(set(data_list) - set(pdf_list))\n",
    "    print(f\"PDFs to download: {len(todownload_list)}\")\n",
    "    for idx, url in enumerate(todownload_list, 1):\n",
    "        pdf_name = url.rsplit('=', 1)[-1]\n",
    "        try:\n",
    "            req = urllib.request.Request(url)\n",
    "            with urllib.request.urlopen(req, context=ssl_context) as response, open(join(path_pdf, pdf_name ), 'wb') as out_file:\n",
    "                out_file.write(response.read())\n",
    "            print(f\"[{idx}/{len(todownload_list)}] Downloaded: {pdf_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{idx}/{len(todownload_list)}] Failed: {pdf_name} ({e})\")\n",
    "\n",
    "def pdf_to_txt(path_pdf, path_txt, path_tmp, poppler_path):\n",
    "    os.chdir(path_tmp)\n",
    "    pdf_list = [join(path_pdf, i) for i in listdir(path_pdf)]\n",
    "    pdf_list = [w.replace(path_pdf, '').replace('.pdf', '') for w in pdf_list]\n",
    "    parsed_list = [join(path_txt, i) for i in listdir(path_txt)]\n",
    "    parsed_list = [w.replace(path_txt, '').replace('.txt', '') for w in parsed_list]\n",
    "    diff_list = list(set(pdf_list) - set(parsed_list))\n",
    "    for idx, file in enumerate(diff_list, 1):\n",
    "        PDF_file = path_pdf + file + '.pdf'\n",
    "        outfile = path_txt + file + '.txt'\n",
    "        try:\n",
    "            pages = convert_from_path(PDF_file, 500, poppler_path=poppler_path)\n",
    "            for i, page in enumerate(pages, 1):\n",
    "                filename = f\"page_{i}.jpg\"\n",
    "                page.save(filename, 'JPEG')\n",
    "            with open(outfile, \"a\") as f:\n",
    "                for i in range(1, len(pages) + 1):\n",
    "                    filename = f\"page_{i}.jpg\"\n",
    "                    text = pytesseract.image_to_string(Image.open(filename)).replace('-\\n', '')\n",
    "                    f.write(text)\n",
    "            print(f\"[{idx}/{len(diff_list)}] Converted: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{idx}/{len(diff_list)}] Failed: {file} ({e})\")\n",
    "\n",
    "def clean_text_column(df, col='columna_unica'):\n",
    "    df[col] = df[col].str.upper()\n",
    "    df[col] = df[col].str.replace('[^a-zA-Z0-9]', ' ', regex=True)\n",
    "    df[col] = df[col].str.strip()\n",
    "    df[col] = df[col].str.replace('   ', ' ', regex=False)\n",
    "    df[col] = df[col].str.replace('  ', ' ', regex=False)\n",
    "    return df\n",
    "\n",
    "def txt_to_bow(path_txt, path_data):\n",
    "    txt_list = [join(path_txt, i) for i in listdir(path_txt)]\n",
    "    txt_list = [w.replace(path_txt, '').replace('.txt', '') for w in txt_list]\n",
    "    df_bow_append = pd.DataFrame()\n",
    "    stop_words = set([\n",
    "        \"ALGÚN\",\"ALGUNA\",\"ALGUNAS\",\"ALGUNO\",\"ALGUNOS\",\"AMBOS\",\"AMPLEAMOS\",\"ANTE\",\"ANTES\",\"AQUEL\",\n",
    "                      \"AQUELLAS\",\"AQUELLOS\",\"AQUI\",\"ARRIBA\",\"ATRAS\",\"BAJO\",\"BASTANTE\",\"BIEN\",\"CADA\",\"CIERTA\",\n",
    "                      \"CIERTAS\",\"CIERTO\",\"CIERTOS\",\"COMO\",\"CON\",\"CONSEGUIMOS\",\"CONSEGUIR\",\"CONSIGO\",\"CONSIGUE\",\n",
    "                      \"CONSIGUEN\",\"CONSIGUES\",\"CUAL\",\"CUANDO\",\"DENTRO\",\"DESDE\",\"DONDE\",\"DOS\",\"EL\",\"ELLAS\",\"ELLOS\",\n",
    "                      \"EMPLEAIS\",\"EMPLEAN\",\"EMPLEAR\",\"EMPLEAS\",\"EMPLEO\",\"EN\",\"ENCIMA\",\"ENTONCES\",\"ENTRE\",\"ERA\",\n",
    "                      \"ERAMOS\",\"ERAN\",\"ERAS\",\"ERES\",\"ES\",\"ESTA\",\"ESTABA\",\"ESTADO\",\"ESTAIS\",\"ESTAMOS\",\"ESTAN\",\"ESTOY\",\n",
    "                      \"FIN\",\"FUE\",\"FUERON\",\"FUI\",\"FUIMOS\",\"GUENO\",\"HA\",\"HACE\",\"HACEIS\",\"HACEMOS\",\"HACEN\",\"HACER\",\"HACES\",\"HAGO\",\n",
    "                      \"INCLUSO\",\"INTENTA\",\"INTENTAIS\",\"INTENTAMOS\",\"INTENTAN\",\"INTENTAR\",\"INTENTAS\",\"INTENTO\",\"IR\",\"LA\",\"LARGO\",\n",
    "                      \"LAS\",\"LO\",\"LOS\",\"MIENTRAS\",\"MIO\",\"MODO\",\"MUCHOS\",\"MUY\",\"NOS\",\"NOSOTROS\",\"OTRO\",\"PARA\",\"PERO\",\"PODEIS\",\n",
    "                      \"PODEMOS\",\"PODER\",\"PODRIA\",\"PODRIAIS\",\"PODRIAMOS\",\"PODRIAN\",\"PODRIAS\",\"POR\",\"POR QUÉ\",\"PORQUE\",\"PRIMERO\",\n",
    "                      \"PUEDE\",\"PUEDEN\",\"PUEDO\",\"QUIEN\",\"SABE\",\"SABEIS\",\"SABEMOS\",\"SABEN\",\"SABER\",\"SABES\",\"SER\",\"SI\",\"SIENDO\",\n",
    "                      \"SIN\",\"SOBRE\",\"SOIS\",\"SOLAMENTE\",\"SOLO\",\"SOMOS\",\"SOY\",\"SU\",\"SUS\",\"TAMBIÉN\",\"TENEIS\",\"TENEMOS\",\"TENER\",\n",
    "                      \"TENGO\",\"TIEMPO\",\"TIENE\",\"TIENEN\",\"TODO\",\"TRABAJA\",\"TRABAJAIS\",\"TRABAJAMOS\",\"TRABAJAN\",\"TRABAJAR\",\"TRABAJAS\",\"TRABAJO\",\n",
    "                      \"TRAS\",\"TUYO\",\"ULTIMO\",\"UN\",\"UNA\",\"UNAS\",\"UNO\",\"UNOS\",\"USA\",\"USAIS\",\"USAMOS\",\"USAN\",\"USAR\",\"USAS\",\"USO\",\"VA\",\"VAIS\",\n",
    "                      \"VALOR\",\"VAMOS\",\"VAN\",\"VAYA\",\"VERDAD\",\"VERDADERA\",\"VERDADERO\",\"VOSOTRAS\",\"VOSOTROS\",\"VOY\",\"YO\",\"ÉL\",\n",
    "                      \"ÉSTA\",\"ÉSTAS\",\"ÉSTE\",\"ÉSTOS\",\"ÚLTIMA\",\"ÚLTIMAS\",\"ÚLTIMO\",\"ÚLTIMOS\",\"A\",\"AÑADIÓ\",\"AÚN\",\"ACTUALMENTE\",\"ADELANTE\",\n",
    "                      \"ADEMÁS\",\"AFIRMÓ\",\"AGREGÓ\",\"AHÍ\",\"AHORA\",\"AL\",\"ALGO\",\"ALREDEDOR\",\"ANTERIOR\",\"APENAS\",\"APROXIMADAMENTE\",\"AQUÍ\",\"ASÍ\",\n",
    "                      \"ASEGURÓ\",\"AUNQUE\",\"AYER\",\"BUEN\",\"BUENA\",\"BUENAS\",\"BUENO\",\"BUENOS\",\"CÓMO\",\"CASI\",\"CERCA\",\"CINCO\",\"COMENTÓ\",\"CONOCER\",\n",
    "                      \"CONSIDERÓ\",\"CONSIDERA\",\"CONTRA\",\"COSAS\",\"CREO\",\"CUALES\",\"CUALQUIER\",\"CUANTO\",\"CUATRO\",\"CUENTA\",\"DA\",\"DADO\",\"DAN\",\"DAR\",\n",
    "                      \"DE\",\"DEBE\",\"DEBEN\",\"DEBIDO\",\"DECIR\",\"DEJÓ\",\"DEL\",\"DEMÁS\",\"DESPUÉS\",\"DICE\",\"DICEN\",\"DICHO\",\"DIERON\",\"DIFERENTE\",\"DIFERENTES\",\n",
    "                      \"DIJERON\",\"DIJO\",\"DIO\",\"DURANTE\",\"E\",\"EJEMPLO\",\"ELLA\",\"ELLO\",\"EMBARGO\",\"ENCUENTRA\",\"ESA\",\"ESAS\",\"ESE\",\"ESO\",\"ESOS\",\n",
    "                      \"ESTÁ\",\"ESTÁN\",\"ESTABAN\",\"ESTAR\",\"ESTARÁ\",\"ESTAS\",\"ESTE\",\"ESTO\",\"ESTOS\",\"ESTUVO\",\"EX\",\"EXISTE\",\"EXISTEN\",\"EXPLICÓ\",\n",
    "                      \"EXPRESÓ\",\"FUERA\",\"GRAN\",\"GRANDES\",\"HABÍA\",\"HABÍAN\",\"HABER\",\"HABRÁ\",\"HACERLO\",\"HACIA\",\"HACIENDO\",\"HAN\",\"HASTA\",\"HAY\",\"HAYA\",\n",
    "                      \"HE\",\"HECHO\",\"HEMOS\",\"HICIERON\",\"HIZO\",\"HOY\",\"HUBO\",\"IGUAL\",\"INDICÓ\",\"INFORMÓ\",\"JUNTO\",\"LADO\",\"LE\",\"LES\",\"LLEGÓ\",\n",
    "                      \"LLEVA\",\"LLEVAR\",\"LUEGO\",\"LUGAR\",\"MÁS\",\"MANERA\",\"MANIFESTÓ\",\"MAYOR\",\"ME\",\"MEDIANTE\",\"MEJOR\",\"MENCIONÓ\",\"MENOS\",\n",
    "                      \"MI\",\"MISMA\",\"MISMAS\",\"MISMO\",\"MISMOS\",\"MOMENTO\",\"MUCHA\",\"MUCHAS\",\"MUCHO\",\"NADA\",\"NADIE\",\"NI\",\n",
    "                      \"NINGÚN\",\"NINGUNA\",\"NINGUNAS\",\"NINGUNO\",\"NINGUNOS\",\"NO\",\"NOSOTRAS\",\"NUESTRA\",\"NUESTRAS\",\"NUESTRO\",\"NUESTROS\",\n",
    "                      \"NUEVA\",\"NUEVAS\",\"NUEVO\",\"NUEVOS\",\"NUNCA\",\"O\",\"OCHO\",\"OTRA\",\"OTRAS\",\"OTROS\",\"PARECE\",\"PARTE\",\"PARTIR\",\"PASADA\",\"PASADO\",\n",
    "                      \"PESAR\",\"POCA\",\"POCAS\",\"POCO\",\"POCOS\",\"PODRÁ\",\"PODRÁN\",\"PODRÍA\",\"PODRÍAN\",\"PONER\",\"POSIBLE\",\"PRÓXIMO\",\"PRÓXIMOS\",\n",
    "                      \"PRIMER\",\"PRIMERA\",\"PRIMEROS\",\"PRINCIPALMENTE\",\"PROPIA\",\"PROPIAS\",\"PROPIO\",\"PROPIOS\",\"PUDO\",\"PUEDA\",\"PUES\",\"QUÉ\",\"QUE\",\n",
    "                      \"QUEDÓ\",\"QUEREMOS\",\"QUIÉN\",\"QUIENES\",\"QUIERE\",\"REALIZÓ\",\"REALIZADO\",\"REALIZAR\",\"RESPECTO\",\"SÍ\",\"SÓLO\",\"SE\",\"SEÑALÓ\",\n",
    "                      \"SEA\",\"SEAN\",\"SEGÚN\",\"SEGUNDA\",\"SEGUNDO\",\"SEIS\",\"SERÁ\",\"SERÁN\",\"SERÍA\",\"SIDO\",\"SIEMPRE\",\"SIETE\",\"SIGUE\",\"SIGUIENTE\",\"SINO\",\n",
    "                      \"SOLA\",\"SOLAS\",\"SOLOS\",\"SON\",\"TAL\",\"TAMPOCO\",\"TAN\",\"TANTO\",\"TENÍA\",\"TENDRÁ\",\"TENDRÁN\",\"TENGA\",\"TENIDO\",\"TERCERA\",\n",
    "                      \"TODA\",\"TODAS\",\"TODAVÍA\",\"TODOS\",\"TOTAL\",\"TRATA\",\"TRAVÉS\",\"TRES\",\"TUVO\",\"USTED\",\"VARIAS\",\"VARIOS\",\"VECES\",\n",
    "                      \"VER\",\"VEZ\",\"Y\",\"YA\",\n",
    "                      \"DE\"\n",
    "    ])\n",
    "\n",
    "    # Prepare contratos_text.csv (overwrite if exists)\n",
    "    output_text_path = join(path_data, 'silver/contratos_text.csv')\n",
    "    with open(output_text_path, 'w', encoding='utf-8-sig') as f:\n",
    "        f.write('file_name|line_number|columna_unica\\n')  # write header only once\n",
    "\n",
    "    for idx, file in enumerate(txt_list, 1):\n",
    "        outfile = path_txt + file + '.txt'\n",
    "        try:\n",
    "            df = pd.read_fwf(outfile, dtype=object, header=None)\n",
    "            list_columns = df.columns\n",
    "            df['file_name'] = file\n",
    "            df['line_number'] = df.index + 1\n",
    "            df['columna_unica'] = ''\n",
    "            for i in list_columns:\n",
    "                df['columna_unica'] = df['columna_unica'].fillna('') + ' ' + df[i].fillna('')\n",
    "            df = clean_text_column(df, 'columna_unica')\n",
    "            df = df[['file_name', 'line_number', 'columna_unica']]\n",
    "            df = df.query('(columna_unica != \"\")')\n",
    "            df.to_csv(output_text_path, mode='a', header=False, sep='|', index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            df['cu_wo_sw'] = [\n",
    "                ' '.join([item for item in x.split() if item not in stop_words])\n",
    "                for x in df['columna_unica']\n",
    "            ]\n",
    "            df['line_text'] = range(1, len(df) + 1)\n",
    "            df_bow = collections.Counter(\n",
    "                [y for x in df.cu_wo_sw.values.flatten() for y in x.split()]\n",
    "            )\n",
    "            df_bow = pd.DataFrame.from_dict(df_bow, orient='index')\n",
    "            df_bow.reset_index(level=0, inplace=True)\n",
    "            df_bow.columns = ['bow', 'freq']\n",
    "            df_bow['file_name'] = file\n",
    "            df_bow['len'] = df_bow['bow'].str.len()\n",
    "            df_bow_append = pd.concat([df_bow_append, df_bow], ignore_index=True)\n",
    "            print(f\"[{idx}/{len(txt_list)}] Parsed: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{idx}/{len(txt_list)}] Error parsing {file}: {e}\")\n",
    "    df_bow_append.to_excel(join(path_data, 'gold/bow_contratos.xlsx'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdd218d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(join(PATH_DATA, 'bronze/CONOSCE_CONTRATOS2025_0.xlsx'), dtype=str)\n",
    "df = df.query('codigoentidad == \"000047\"')\n",
    "contract_list = df['urlcontrato']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bfe8cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs to download: 24\n",
      "[1/24] Downloaded: 85ce2e6b-4f25-4ab7-b789-9cb641262172.pdf\n",
      "[2/24] Downloaded: 796855d7-663b-45d9-90fa-1826c372ee56.pdf\n",
      "[3/24] Downloaded: beabb84f-5fa3-4ab5-ae24-c01f60a459a6.pdf\n",
      "[4/24] Downloaded: ee038584-d734-4c54-a7db-83a879453532.pdf\n",
      "[5/24] Downloaded: b7fc6c18-f5c4-453f-9ec5-a8078f7ea0ca.pdf\n",
      "[6/24] Downloaded: 8541d3dc-1d7a-40d9-adc6-346af9faecb2.pdf\n",
      "[7/24] Downloaded: d73ecf69-9b93-4b84-94fc-6a46235e689a.pdf\n",
      "[8/24] Downloaded: bad4b9f0-f33f-4182-850e-ed2c4b76bdd4.pdf\n",
      "[9/24] Downloaded: 5b59ae63-d336-49ef-927e-123e3452cc53.pdf\n",
      "[10/24] Downloaded: 659e7ca5-54b4-40f4-9066-ecc8ade6743a.pdf\n",
      "[11/24] Downloaded: 834c6dbf-2dbb-4469-bc06-94e73e500d40.pdf\n",
      "[12/24] Downloaded: d9c25bee-4dba-4b6c-92f4-cc0836eaac64.pdf\n",
      "[13/24] Downloaded: 3ba41be6-7653-4824-8c28-00da3711882b.pdf\n",
      "[14/24] Downloaded: da97c5b1-b66a-4308-9796-5912c4e60cd4.pdf\n",
      "[15/24] Downloaded: fbad6e70-934f-491d-8bb3-043d3c1cf800.pdf\n",
      "[16/24] Downloaded: 93b42373-06c1-4cf7-a2fc-5759edfae8f4.pdf\n",
      "[17/24] Downloaded: 02833e39-3d26-417a-a2d1-52f3b80df264.pdf\n",
      "[18/24] Downloaded: 47585f1c-16ae-4bed-9687-ddaa556ad211.pdf\n",
      "[19/24] Downloaded: 974c6af2-9b77-4f3c-905f-58021bbbe66b.pdf\n",
      "[20/24] Downloaded: e4fd3057-f771-4f4d-a457-469443e2de6e.pdf\n",
      "[21/24] Downloaded: 45e90837-55da-4a57-bb26-8af9c249a35e.pdf\n",
      "[22/24] Downloaded: a3b87479-8e6a-49ed-935c-ed6067a54729.pdf\n",
      "[23/24] Downloaded: 48fdb45c-1f41-435e-a38b-7a42a46a0040.pdf\n",
      "[24/24] Downloaded: 24dddc44-fb64-40e4-bb2b-0d6ad01766ff.pdf\n"
     ]
    }
   ],
   "source": [
    "download_pdfs(contract_list, PATH_PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c792e715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] Failed: # (place your PDF files here) (Unable to get page count.\n",
      "I/O Error: Couldn't open file '/workspace/pdf/# (place your PDF files here).pdf': No such file or directory.\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "pdf_to_txt(PATH_PDF, PATH_TXT, PATH_TMP, POPPLER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c6510e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25] Error parsing # (output TXT files): [Errno 2] No such file or directory: '/workspace/text/# (output TXT files).txt'\n",
      "[2/25] Parsed: 02833e39-3d26-417a-a2d1-52f3b80df264\n",
      "[3/25] Parsed: 24dddc44-fb64-40e4-bb2b-0d6ad01766ff\n",
      "[4/25] Parsed: 3ba41be6-7653-4824-8c28-00da3711882b\n",
      "[5/25] Parsed: 45e90837-55da-4a57-bb26-8af9c249a35e\n",
      "[6/25] Parsed: 47585f1c-16ae-4bed-9687-ddaa556ad211\n",
      "[7/25] Parsed: 48fdb45c-1f41-435e-a38b-7a42a46a0040\n",
      "[8/25] Parsed: 5b59ae63-d336-49ef-927e-123e3452cc53\n",
      "[9/25] Parsed: 659e7ca5-54b4-40f4-9066-ecc8ade6743a\n",
      "[10/25] Parsed: 796855d7-663b-45d9-90fa-1826c372ee56\n",
      "[11/25] Parsed: 834c6dbf-2dbb-4469-bc06-94e73e500d40\n",
      "[12/25] Parsed: 8541d3dc-1d7a-40d9-adc6-346af9faecb2\n",
      "[13/25] Parsed: 85ce2e6b-4f25-4ab7-b789-9cb641262172\n",
      "[14/25] Parsed: 93b42373-06c1-4cf7-a2fc-5759edfae8f4\n",
      "[15/25] Parsed: 974c6af2-9b77-4f3c-905f-58021bbbe66b\n",
      "[16/25] Parsed: a3b87479-8e6a-49ed-935c-ed6067a54729\n",
      "[17/25] Parsed: b7fc6c18-f5c4-453f-9ec5-a8078f7ea0ca\n",
      "[18/25] Parsed: bad4b9f0-f33f-4182-850e-ed2c4b76bdd4\n",
      "[19/25] Parsed: beabb84f-5fa3-4ab5-ae24-c01f60a459a6\n",
      "[20/25] Parsed: d73ecf69-9b93-4b84-94fc-6a46235e689a\n",
      "[21/25] Parsed: d9c25bee-4dba-4b6c-92f4-cc0836eaac64\n",
      "[22/25] Parsed: da97c5b1-b66a-4308-9796-5912c4e60cd4\n",
      "[23/25] Parsed: e4fd3057-f771-4f4d-a457-469443e2de6e\n",
      "[24/25] Parsed: ee038584-d734-4c54-a7db-83a879453532\n",
      "[25/25] Parsed: fbad6e70-934f-491d-8bb3-043d3c1cf800\n"
     ]
    }
   ],
   "source": [
    "txt_to_bow(PATH_TXT, PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76256bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
